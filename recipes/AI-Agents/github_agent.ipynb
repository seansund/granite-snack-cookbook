{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "introduction"
   },
   "source": [
    "# Building a GitHub Agent with LangGraph and LangChain\n",
    "\n",
    "This notebook guides you through building an intelligent agent that can interact with GitHub repositories. Using LangGraph, LangChain, and IBM's Granite LLM, you'll create an agent capable of performing various GitHub operations through natural language instructions.\n",
    "\n",
    "## What You'll Learn\n",
    "- How to set up API connections to GitHub\n",
    "- How to serve and interact with an LLM (IBM Granite)\n",
    "- How to create tools that interact with GitHub's API\n",
    "- How to build a ReAct agent that can reason about GitHub tasks\n",
    "\n",
    "## Prerequisites\n",
    "- GitHub account with a repository you want the agent to access\n",
    "- Either a local Ollama server or a Replicate API token\n",
    "- Basic understanding of Python and LLMs\n",
    "\n",
    "Let's start by insuring we are using Python 3.10, 3.11, or 3.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f8o9Ga6mBAus"
   },
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "assert sys.version_info >= (3, 10) and sys.version_info < (3, 13), \"Use Python 3.10, 3.11 or 3.12 to run this notebook.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D4C5FZicBAut"
   },
   "source": [
    "and Installing some dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "wHsVa-PXBhfz"
   },
   "outputs": [],
   "source": [
    "! pip install langgraph\n",
    "! pip install --upgrade --quiet pygithub langchain-community replicate\n",
    "! pip install git+https://github.com/ibm-granite-community/utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to GitHub\n",
    "\n",
    "For your agent to interact with GitHub, it needs proper authentication. We'll use GitHub Apps for this purpose, which provides a secure way to access repositories.\n",
    "\n",
    "### Setting Up Your GitHub App\n",
    "\n",
    "1. Follow the instructions [here](https://docs.github.com/en/apps/creating-github-apps/registering-a-github-app/registering-a-github-app) to create a GitHub App\n",
    "2. Configure the following permissions for your app:\n",
    "   - Repository contents: Read & Write\n",
    "   - Issues: Read & Write\n",
    "   - Pull requests: Read & Write\n",
    "3. Generate a private key for your app\n",
    "4. Install the app to your repository\n",
    "\n",
    "After setting up your GitHub App, you'll need three pieces of information:\n",
    "- Your repository name in the format `username/repo-name`\n",
    "- The private key file (downloaded when you created the app). You will need to upload the key to your local filestore and input the path to the key file.\n",
    "- The GitHub App ID (found in your app's settings)\n",
    "\n",
    "Let's set these as environment variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3zzffpEQES1x"
   },
   "source": [
    "## Environment Setup\n",
    "\n",
    "This notebook needs some environment variables set to necessary information.\n",
    "\n",
    "1. Using a `.env` file in the working directory when running the notebook (recommended)\n",
    "2. Setting environment variables manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Option 1: Using a .env File\n",
    "\n",
    "Create a `.env` file in the working directory used when running this notebook with the following variables:\n",
    "\n",
    "```\n",
    "# GitHub credentials\n",
    "GITHUB_REPOSITORY=your/githubrepo\n",
    "GITHUB_APP_PRIVATE_KEY=your/private_key.pem\n",
    "GITHUB_APP_ID=your_github_app_id\n",
    "\n",
    "# LLM credentials (if using Replicate)\n",
    "REPLICATE_API_TOKEN=your_replicate_api_token\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fTqugmeKFjde"
   },
   "source": [
    "### Option 2: Manual Environment Setup (Recommended when using Colab)\n",
    "\n",
    "If you didn't set up a `.env` file, you can set them directly here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Qq5fVJMFhSA"
   },
   "outputs": [],
   "source": [
    "from ibm_granite_community.notebook_utils import get_env_var\n",
    "\n",
    "# If you need to manually set environment variables and are not using a .env file\n",
    "# you will need to edit the following lines to set the environment variables to your specific\n",
    "# values. get_env_var will set the environment variable to the value if there is no value available\n",
    "# in the environment, a .env file, or Google Colab secrets.\n",
    "\n",
    "# Edit these lines to set the second parameter to your values.\n",
    "get_env_var(\"GITHUB_REPOSITORY\", \"your/githubrepo\")\n",
    "get_env_var(\"GITHUB_APP_ID\", \"your_github_app_id\")\n",
    "get_env_var(\"GITHUB_APP_PRIVATE_KEY\", \"your/private_key.pem\") #you will need to upload your .pem folder into the colab file store,located in the left hand toolbar. You will then replace this value with the path to your .pem key\n",
    "\n",
    "# Or set the key content directly (not recommended for security reasons):\n",
    "# get_env_var(\"GITHUB_APP_PRIVATE_KEY\", \"\"\"-----BEGIN RSA PRIVATE KEY-----\n",
    "# ...\n",
    "# -----END RSA PRIVATE KEY-----\"\"\")\n",
    "\n",
    "# For Replicate (if you're not using Ollama):\n",
    "# get_env_var(\"REPLICATE_API_TOKEN\", \"your_replicate_api_token\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Tlp8yuQBAut"
   },
   "source": [
    "## Setting Up the LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Our agent needs an LLM to generate responses and make decisions. We'll use IBM's Granite model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Setting Up Replicate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To get set up with Replicate, see [Getting Started with Replicate](https://github.com/ibm-granite-community/granite-kitchen/blob/main/recipes/Getting_Started/Getting_Started_with_Replicate.ipynb).\n",
    "\n",
    "To connect to a model on a provider other than Replicate, substitute this code cell with one from the [LLM component recipe](https://github.com/ibm-granite-community/granite-kitchen/blob/main/recipes/Components/Langchain_LLMs.ipynb).\n",
    "\n",
    "Let's set up our LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WwOeYK5Hdm6q"
   },
   "outputs": [],
   "source": [
    "from langchain_community.llms import Replicate\n",
    "\n",
    "# Initialize Replicate\n",
    "llm = Replicate(\n",
    "    model=\"ibm-granite/granite-3.2-8b-instruct\",\n",
    "    replicate_api_token=get_env_var(\"REPLICATE_API_TOKEN\"),\n",
    "    model_kwargs={\n",
    "        \"max_tokens\": 2000,  # Set the maximum number of tokens to generate as output.\n",
    "        \"min_tokens\": 200,  # Set the minimum number of tokens to generate as output.\n",
    "        \"temperature\": 0.75,\n",
    "        \"presence_penalty\": 0,\n",
    "        \"frequency_penalty\": 0,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0raS-PQdBAuu"
   },
   "source": [
    "## Testing the LLM\n",
    "\n",
    "Before building our agent, it's a good idea to test the LLM to make sure it's working properly. This simple test ensures that we can connect to either Ollama or Replicate and that the model responds as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test_llm_cell"
   },
   "outputs": [],
   "source": [
    "# Test the LLM to make sure it's working\n",
    "llm.invoke(\"Hello, what can you help me with today?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GOH9cERwBAuu"
   },
   "source": [
    "## Creating the GitHub Toolkit\n",
    "\n",
    "Now that we have our GitHub credentials and LLM set up, let's create the GitHub toolkit. This toolkit provides a set of tools that our agent can use to interact with GitHub.\n",
    "\n",
    "LangChain provides a convenient `GitHubToolkit` class that wraps around the GitHub API. Let's initialize it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L6xj5d9L4LoQ"
   },
   "outputs": [],
   "source": [
    "from langchain_community.agent_toolkits.github.toolkit import GitHubToolkit\n",
    "from langchain_community.utilities.github import GitHubAPIWrapper\n",
    "\n",
    "github = GitHubAPIWrapper()\n",
    "toolkit = GitHubToolkit.from_github_api_wrapper(github)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lnetCLVBBAuu"
   },
   "source": [
    "## Exploring Available GitHub Tools\n",
    "\n",
    "Let's explore the tools that are available in our GitHub toolkit. Each tool represents a specific action our agent can take on GitHub, such as creating an issue, commenting on a pull request, or reading file contents.\n",
    "\n",
    "This step helps us understand what our agent is capable of doing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sHkCEGi9-I5M"
   },
   "outputs": [],
   "source": [
    "tools = toolkit.get_tools()\n",
    "print(\"Available tools:\")\n",
    "for tool in tools:\n",
    "    print(f\"- {tool.name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fcEKXcsfBAuu"
   },
   "source": [
    "## Building the ReAct Agent\n",
    "\n",
    "Now we're ready to build our GitHub agent! We'll use the ReAct (Reasoning and Acting) framework, which allows our agent to:\n",
    "\n",
    "1. Think about what it should do (Reasoning)\n",
    "2. Take an action using one of the GitHub tools (Acting)\n",
    "3. Observe the result of that action\n",
    "4. Reason about what to do next based on those observations\n",
    "\n",
    "This approach allows the agent to break down complex GitHub tasks into a series of steps.\n",
    "\n",
    "We'll start by defining a prompt template that instructs the LLM on how to use the ReAct framework:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XhTtEHeNAtxa"
   },
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "from langchain.agents.react.agent import create_react_agent\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"You are a helpful GitHub assistant who can perform various actions on GitHub repositories.\n",
    "You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, must be one of [{tool_names}]\n",
    "Action Input: input passed to tool\n",
    "Observation: action result\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "Thought: {agent_scratchpad}\n",
    "\"\"\"\n",
    "\n",
    "# Create the prompt template\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"input\", \"agent_scratchpad\"],\n",
    "    partial_variables={\n",
    "        \"tools\": lambda x: format_tool_string(tools),\n",
    "        \"tool_names\": lambda x: \", \".join([tool.name for tool in tools]),\n",
    "    },\n",
    ")\n",
    "\n",
    "# Helper function to format tools\n",
    "def format_tool_string(tools):\n",
    "    return \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in tools])\n",
    "\n",
    "# Create a memory to maintain conversation context\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# Instantiate the ReAct agent using LangChain's create_react_agent\n",
    "agent = create_react_agent(\n",
    "    llm,\n",
    "    tools,\n",
    "    prompt,\n",
    ")\n",
    "\n",
    "# Create an agent executor with the ReAct agent\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    memory=memory,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ibQvt_yzBAuv"
   },
   "source": [
    "## Creating a Helper Function to Run the Agent\n",
    "\n",
    "Now that our agent is set up, let's create a helper function that makes it easy to run the agent with different queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tjbm-dtjGl1U"
   },
   "outputs": [],
   "source": [
    "def run_github_agent(query):\n",
    "    \"\"\"Run the GitHub agent with a user query.\"\"\"\n",
    "    result = agent_executor.invoke({\"input\": query})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1avL4KJmBAuv"
   },
   "source": [
    "## Testing the GitHub Agent\n",
    "\n",
    "Now that our agent is fully set up, let's test it with a simple query. This example asks the agent to count the number of issues in the repository:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xAFJHz8FDnhK"
   },
   "outputs": [],
   "source": [
    "result = run_github_agent(\"How many issues are in the repository?\")\n",
    "print(result[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RHUQ_3TzBAuv"
   },
   "source": [
    "## Example Use Cases\n",
    "\n",
    "Here are some example queries you can try with your GitHub agent:\n",
    "\n",
    "```python\n",
    "# Get information about repositories\n",
    "run_github_agent(\"List all the files in the repository\")\n",
    "run_github_agent(\"What are the most recent commits?\")\n",
    "\n",
    "# Work with issues\n",
    "run_github_agent(\"Create a new issue titled 'Update documentation' with description 'We need to update the README file'\")\n",
    "run_github_agent(\"List all open issues\")\n",
    "run_github_agent(\"Close issue #1\")\n",
    "\n",
    "# Work with pull requests\n",
    "run_github_agent(\"List all open pull requests\")\n",
    "run_github_agent(\"Comment on pull request #2 saying 'Looks good, approved!'\")\n",
    "\n",
    "# Work with file contents\n",
    "run_github_agent(\"What's in the README.md file?\")\n",
    "run_github_agent(\"Create a new file called 'hello.txt' with content 'Hello, world!'\")\n",
    "```\n",
    "\n",
    "Feel free to experiment with different queries based on your repository's contents and what you want to accomplish!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kgpb0VV5BAuv"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "Congratulations! You've built a functional GitHub agent that can interact with your repository using natural language instructions. This agent demonstrates the power of combining LLMs with API tools to create useful AI assistants.\n",
    "\n",
    "### What You've Learned\n",
    "- How to set up GitHub App authentication\n",
    "- How to connect to and utilize an LLM (IBM Granite)\n",
    "- How to create a ReAct agent that can reason about and execute GitHub operations\n",
    "- How to use LangChain and LangGraph to create an AI agent with tool-using capabilities\n",
    "\n",
    "### Next Steps\n",
    "- Try more complex queries and see how the agent handles them\n",
    "- Add more specialized tools for specific GitHub operations\n",
    "- Integrate this agent with other services like Slack or Discord\n",
    "- Refine the agent's prompt to make it better at specific tasks"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
