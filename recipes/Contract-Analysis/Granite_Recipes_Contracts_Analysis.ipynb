{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contract Analysis using IBM Granite LLM from watsonx\n",
    "Author: [@Aisha Mohammed Farooq Darga](https://www.linkedin.com/in/aisha-mohammed-farooq-darga-778280135/)\n",
    "\n",
    "### **Description**\n",
    "\n",
    "Contract analysis involves reviewing, interpreting, and extracting key information from contract documents to identify risks, obligations, and critical aspects. This ensures clarity on terms and conditions, helps avoid ambiguities, and mitigates potential legal or financial complications. \n",
    "\n",
    "Effective contract analysis is crucial for businesses, legal professionals, and stakeholders, as it safeguards against unintentional obligations, disputes, and risks.\n",
    "\n",
    "---\n",
    "\n",
    "### **What Does This Notebook Do?**\n",
    "\n",
    "This notebook provides an **automated solution for contract analysis** by leveraging advanced AI technologies like **IBM Granite LLM (`ibm/granite-3-8b-instruct`)** and **[Docling's DocumentConverter](https://ds4sd.github.io/docling/)**. It simplifies the process of extracting, analyzing, and understanding key details from contract documents, enabling users to:  \n",
    "- Identify important clauses and terms.  \n",
    "- Assess potential risks and obligations.  \n",
    "- Generate actionable insights for better decision-making.  \n",
    "\n",
    "The notebook is particularly useful for legal professionals, business analysts, and organizations handling contracts regularly, as it ensures consistency and scalability in the analysis process.  \n",
    "\n",
    "---\n",
    "\n",
    "### **Approach Followed**\n",
    "\n",
    "1. **Document Conversion**  \n",
    "   - Contracts in various file formats (e.g., PDFs) are converted into text using **Docling's DocumentConverter**, producing markdown-formatted text for seamless processing.  \n",
    "\n",
    "2. **Text Splitting and Preparation**  \n",
    "   - Contracts are split into manageable text chunks to ensure efficient processing by the AI model and adherence to token limits.  \n",
    "\n",
    "3. **AI-Powered Analysis**  \n",
    "   - The **IBM Granite LLM (`ibm/granite-3-8b-instruct`)** processes the contract chunks using a carefully crafted prompt. It performs the following tasks:\n",
    "     - **Clause Identification**: Extracts and summarizes critical clauses, such as payment terms, intellectual property rights, and termination conditions.  \n",
    "     - **Risk Analysis**: Identifies potential risks, categorizes them by severity, and offers strategies to mitigate them.  \n",
    "     - **Actionable Recommendations**: Suggests improvements to contract terms and provides compliance checklists.  \n",
    "\n",
    "4. **Output Consolidation**  \n",
    "   - The results from each chunk are merged into a single comprehensive analysis document, offering both a high-level summary and detailed insights.  \n",
    "\n",
    "---\n",
    "\n",
    "### **Prerequisites**\n",
    "\n",
    "- **IBM Cloud Account**: [Sign up here](https://cloud.ibm.com/registration).\n",
    "- **Python Version**: Ensure Python 3.11.9 is installed.\n",
    "\n",
    "---\n",
    "\n",
    "### **Environment Setup**\n",
    "\n",
    "#### 1. **IBM Cloud Account Setup**\n",
    "- Log in to [watsonx.ai](https://dataplatform.cloud.ibm.com/registration/stepone?context=wx&apps=all).\n",
    "- Create a [watsonx.ai Project](https://www.ibm.com/docs/en/watsonx/saas?topic=projects-creating-project).\n",
    "- Create a [Jupyter Notebook](https://www.ibm.com/docs/en/watsonx/saas?topic=editor-creating-managing-notebooks).\n",
    "This step will open a Notebook environment where you can copy the code from this tutorial.  Alternatively, you can download this notebook to your local system and upload it to your watsonx.ai project as an asset.\n",
    "\n",
    "#### 2. **Watson Machine Learning (WML) Service**\n",
    "- Create a [WML Service Instance](https://cloud.ibm.com/catalog/services/watson-machine-learning) (Lite Plan recommended).\n",
    "- Generate an [API Key](https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/ml-authentication.html).\n",
    "- Associate the WML service to the project that you created in [watsonx.ai](https://dataplatform.cloud.ibm.com/docs/content/wsj/getting-started/assoc-services.html).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Code Implementation**:\n",
    "\n",
    "### **1. Install Libraries**\n",
    "We start by installing the required dependencies. This includes libraries for document conversion, IBM watsonx LLM integration, and data handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q git+https://github.com/ibm-granite-community/utils \\\n",
    "    docling==2.14.0 \\\n",
    "    langchain==0.2.12 \\\n",
    "    langchain-ibm==0.1.11 \\\n",
    "    langchain-community==0.2.11 \\\n",
    "    langchain-core==0.2.28 \\\n",
    "    ibm-watsonx-ai==1.1.2 \\\n",
    "    transformers==4.47.1 \\\n",
    "    replicate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Import Libraries**\n",
    "\n",
    "In this step, we import the necessary libraries that will help us process the contract data and analyze it using watsonx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import logging\n",
    "from docling.document_converter import DocumentConverter\n",
    "from langchain_ibm import WatsonxLLM\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from ibm_granite_community.notebook_utils import get_env_var\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Configure Logging**\n",
    "\n",
    "In this step, we configure the logging settings. Logging is essential for debugging and tracking the notebook's execution. The logging level is set to `INFO`, which allows us to capture useful information during the execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging configuration for debugging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Initialize Utilities**\n",
    "\n",
    "Here, we initialize the **DocumentConverter** instance. This utility is responsible for converting contract documents into a structured format that can be processed and analyzed in the next steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DocumentConverter for converting documents\n",
    "document_converter = DocumentConverter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5. Define Functions**\n",
    "\n",
    "#### 5.1 Read Contract Text from a File\n",
    "This function reads the contract from a specified file path, converts it using the `DocumentConverter`, and exports the contract text in markdown format for easier analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_contract(file_path):\n",
    "    result = document_converter.convert(file_path)\n",
    "    text_content = result.document.export_to_markdown()\n",
    "    return text_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Split Text into Manageable Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(text, max_tokens=100000):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "\n",
    "    for word in words:\n",
    "        word_length = len(word) + 1  # +1 for the space\n",
    "        if current_length + word_length > max_tokens:\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "            current_chunk = []\n",
    "            current_length = 0\n",
    "        current_chunk.append(word)\n",
    "        current_length += word_length\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Generate Contract Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_analysis_with_watsonx(text, watson_llm, tokenizer):\n",
    "    chunks = split_text(text, max_tokens=100000)\n",
    "    logger.info(f\"Split text into {len(chunks)} chunks for processing.\")\n",
    "    results = []\n",
    "    \n",
    "    for i, chunk in enumerate(chunks):\n",
    "        logger.info(f\"Processing chunk {i + 1} of {len(chunks)}...\")\n",
    "        prompt = tokenizer.apply_chat_template(\n",
    "            conversation=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": (\n",
    "                        \"Analyze the following contract text and provide a structured report with the following sections:\\n\\n\"\n",
    "                        \"1. General Overview \\n\"\n",
    "                        \"2. Key Highlights \\n\"\n",
    "                        \"3. Recommendations and Actionable Insights \\n\"\n",
    "                        \"4. Compliance Checklist \\n\"\n",
    "                        \"5. Summary of Risks by Severity: Present a table summarizing risks, severity, and mitigation strategies.\\n\\n\"\n",
    "                        f\"Contract Text:\\n{chunk}\"\n",
    "                    ),\n",
    "                }\n",
    "            ],\n",
    "            add_generation_prompt=True,\n",
    "            tokenize=False,\n",
    "        )\n",
    "        result = watson_llm.invoke(prompt)\n",
    "        results.append(result)\n",
    "    \n",
    "    return \"\\n\\n\".join(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4 Directory and File Management\n",
    "\n",
    "These helper functions assist in managing files and directories. We use them to:\n",
    "- **setup_directory**: Ensure the necessary directory exists.\n",
    "- **download_file**: Download contract files from a specified URL.\n",
    "- **cleanup_directory**: Remove files from the directory after processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_directory(directory):\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    logger.info(f\"Directory '{directory}' is ready.\")\n",
    "\n",
    "def download_file(file_url, destination):\n",
    "    response = requests.get(file_url)\n",
    "    if response.status_code == 200:\n",
    "        with open(destination, \"wb\") as file:\n",
    "            file.write(response.content)\n",
    "        logger.info(f\"Downloaded: {destination}\")\n",
    "    else:\n",
    "        logger.error(f\"Failed to download {file_url}. Status code: {response.status_code}\")\n",
    "\n",
    "def cleanup_directory(directory):\n",
    "    for file_name in os.listdir(directory):\n",
    "        file_path = os.path.join(directory, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "    os.rmdir(directory)\n",
    "    logger.info(f\"Cleaned up directory '{directory}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Main Execution Block\n",
    "\n",
    "#### 6.1 Setup Environment Variables and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Setup environment variables\n",
    "ibm_cloud_api_key = get_env_var('WATSONX_APIKEY')\n",
    "project_id = get_env_var('WATSONX_PROJECT_ID')\n",
    "watson_url = get_env_var('WATSONX_URL')\n",
    "\n",
    "watson_llm = WatsonxLLM(\n",
    "    model_id=\"ibm/granite-3-8b-instruct\",\n",
    "    apikey=ibm_cloud_api_key,\n",
    "    project_id=project_id,\n",
    "    params={\n",
    "        \"decoding_method\": \"greedy\",\n",
    "        \"max_new_tokens\": 8000,\n",
    "        \"min_new_tokens\": 1,\n",
    "        \"repetition_penalty\": 1.01,\n",
    "    },\n",
    "    url=watson_url,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2 Setup Directory and Download Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"ibm-granite/granite-3.1-8b-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    \n",
    "data_dir = \"Contracts\"\n",
    "setup_directory(data_dir)\n",
    "\n",
    "local_paths = [\n",
    "    \"IT_Consultancy_Agreement.pdf\",\n",
    "    \"Construction_Contract.pdf\",\n",
    "    \"Employment_Agreement.pdf\",\n",
    "    \"Software_Development_Contract.pdf\"\n",
    "]\n",
    "base_url = \"https://raw.githubusercontent.com/AishaDarga/granite-snack-cookbook/refs/heads/contract-analysis/recipes/Contract-Analysis/Contracts/\"\n",
    "\n",
    "for file_name in local_paths:\n",
    "    file_url = base_url + file_name\n",
    "    file_path = os.path.join(data_dir, file_name)\n",
    "    download_file(file_url, file_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3 Read, Process, and Analyze Contracts\n",
    "\n",
    "**Note:** You can change the selected contract file to any other contract present in the `Contracts` folder. Simply replace 'selected_contract' in the script with the desired contract file name.\n",
    "\n",
    "The generated output contains the following sections:\n",
    "\n",
    "1. General Overview:\n",
    "   - Key contract details such as the effective dates, involved parties, and scope of work.\n",
    "\n",
    "2. Key Highlights:\n",
    "   - Summarizes the important contract clauses including payment terms, intellectual property rights, termination provisions, and dispute resolution methods.\n",
    "\n",
    "3. Detailed Risk Analysis:\n",
    "   - Identifies and assesses potential risks within each key section of the contract, categorizing them as Low, Medium, High, or Critical.\n",
    "\n",
    "4. Recommendations and Actionable Insights:\n",
    "   - Provides practical advice for mitigating risks and improving contract terms.\n",
    "\n",
    "5. Compliance Checklist:\n",
    "   - Lists compliance requirements and any unaddressed risks.\n",
    "\n",
    "6. Summary of Risks by Severity:\n",
    "   - A table summarizing identified risks, their severity, and proposed mitigation strategies.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_contract = \"Employment_Agreement.pdf\"\n",
    "if selected_contract in local_paths:\n",
    "    file_path = os.path.join(data_dir, selected_contract)\n",
    "    contract_text = read_contract(file_path)\n",
    "    contract_analysis = generate_analysis_with_watsonx(contract_text, watson_llm, tokenizer)\n",
    "    print(f\"Analysis for {selected_contract}:\\n{contract_analysis}\")\n",
    "else:\n",
    "    print(f\"Error: {selected_contract} not found in the available contracts.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4 Cleanup\n",
    "\n",
    "Once the contract analysis is complete, we use the cleanup function to remove the downloaded contract files and clean up the directory, ensuring no unnecessary files remain on the system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup_directory(data_dir)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
